<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1 plus MathML 2.0//EN" "http://www.w3.org/Math/DTD/mathml2/xhtml-math11-f.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta name="GENERATOR" content="LyX 2.3.6" />
<meta http-equiv="Content-type" content="text/html;charset=UTF-8" />
<title>LyX Document</title>
<style type='text/css'>
/* Layout-provided Styles */
del.strikeout {
  text-decoration: line-through;
}
div.standard {
	margin-bottom: 2ex;
}
h2.section_ {
font-weight: bold;
font-size: x-large;
margin-top: 1.3ex;
margin-bottom: 0.7ex;
text-align: left;

}
ul.itemize {
margin-top: 0.7ex;
margin-bottom: 0.7ex;
margin-left: 3ex;
text-align: left;

}
div.plain_layout {
text-align: left;

}
span.flex_url {
font-family: monospace;
}


</style>
</head>
<body dir="auto">


<div class="standard" id='magicparlabel-20'><br />
</div>
<h2 class="section_" id='magicparlabel-21'>Reading list</h2>
<div class="standard" id='magicparlabel-22'>These lecture Handouts have been derived based on the above reading list.</div>

<div class="standard" id='magicparlabel-23'><u>Main texts:</u></div>

<ul class="itemize" id='magicparlabel-24'><li class="itemize_item">Bishop, C. M. (2006). Pattern recognition and machine learning. New York: Springer.

<ul class="itemize" id='magicparlabel-25'><li class="itemize_item">It is a classical textbook in machine learning (ML) methods. It discusses all the concepts introduced in the course (not necessarily in the same depth). It is one of the main textbooks in the module. The level on difficulty is easy.</li>
<li class="itemize_item">Students who wish to have a textbook covering traditional concepts in machine learning are suggested to get a copy of this textbook. It is available online from the Microsoft's website <span class="flex_url">https://www.microsoft.com/en-us/research/publication/pattern-recognition-machine-learning/</span></li>
</ul>
</li><li class="itemize_item">Shalev-Shwartz, S., &amp; Ben-David, S. (2014). Understanding machine learning: From theory to algorithms. Cambridge university press. 

<ul class="itemize" id='magicparlabel-32'><li class="itemize_item">It has several elements of theory about machine learning algorithms. It is one of the main textbooks in the module. The level on difficulty is advanced as it requires moderate knowledge of maths.</li>
</ul>
</li><li class="itemize_item">Bishop, C. M. (1995). Neural networks for pattern recognition. Oxford university press.

<ul class="itemize" id='magicparlabel-34'><li class="itemize_item">It is a classical textbook about `traditional' artificial neural networks (ANN). It is very comprehensive (compared to others) and it goes deep enough for the module although it may be a bit outdated. It is one of the main textbooks in the module for ANN. The level on difficulty is moderate.</li>
</ul>
</li></ul>
<div class="standard" id='magicparlabel-35'><u>Supplementary textbooks:</u></div>

<ul class="itemize" id='magicparlabel-36'><li class="itemize_item">Ripley, B. D. (2007). Pattern recognition and neural networks. Cambridge university press.

<ul class="itemize" id='magicparlabel-37'><li class="itemize_item">A classical textbook in artificial neural networks (ANN) that also covers other machine learning concepts. It contains interesting theory about ANN. </li>
<li class="itemize_item">It is suggested to be used as a supplementary reading for neural networks as it contains a few interesting theoretical results. The level on difficulty is moderate.</li>
</ul>
</li><li class="itemize_item">Williams, C. K., &amp; Rasmussen, C. E. (2006). Gaussian processes for machine learning (Vol. 2, No. 3, p. 4). Cambridge, MA: MIT press.

<ul class="itemize" id='magicparlabel-40'><li class="itemize_item">A classic book in Gaussian process regression (GPR) that covers the material we will discuss in the course about GPR. It can be used as a companion textbook with that of (Bishop, C. M., 2006). The level on difficulty is easy.</li>
</ul>
</li><li class="itemize_item">Murphy, K. P. (2012). Machine learning: a probabilistic perspective. MIT press.

<ul class="itemize" id='magicparlabel-42'><li class="itemize_item">A popular textbook in machine learning methods. It discusses all the concepts introduced in the module. It focuses more on the probabilistic/Bayesian framework but not with great detail. It can be used as a comparison textbook for brief reading about ML methods just to see another perspective than that in (Bishop, C. M., 2006). The level on difficulty is easy.</li>
</ul>
</li><li class="itemize_item">Murphy, K. P. (2022). Probabilistic machine learning: an introduction. MIT press.

<ul class="itemize" id='magicparlabel-44'><li class="itemize_item">A textbook in machine learning methods. It covers a smaller number of ML concepts than (Murphy, K. P., 2012) but it contains more fancy/popular topics such as deep learning ideas. It is suggested to be used in the same manner as (Murphy, K. P., 2012). The level on difficulty is easy.</li>
</ul>
</li><li class="itemize_item">Barber, D. (2012). Bayesian reasoning and machine learning. Cambridge University Press.

<ul class="itemize" id='magicparlabel-46'><li class="itemize_item">A textbook in machine learning methods from a Bayesian point of view. It discusses all the concepts introduced apart from ANN and stochastic gradient algorithms. It aims to be more `statistical' than those of Murphy and Bishop. The level on difficulty is easy.</li>
</ul>
</li><li class="itemize_item">Devroye, L., Gy√∂rfi, L., &amp; Lugosi, G. (2013). A probabilistic theory of pattern recognition (Vol. 31). Springer Science &amp; Business Media.

<ul class="itemize" id='magicparlabel-48'><li class="itemize_item">Theoretical aspects about machine learning algorithms. The level on difficulty is advanced as it requires moderate knowledge of probability.</li>
</ul>
</li></ul>
</body>
</html>
